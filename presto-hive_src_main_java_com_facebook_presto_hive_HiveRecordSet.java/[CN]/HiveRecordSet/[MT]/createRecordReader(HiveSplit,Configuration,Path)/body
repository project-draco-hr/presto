{
  final InputFormat<?,?> inputFormat=getInputFormat(configuration,split.getSchema(),true);
  final JobConf jobConf=new JobConf(configuration);
  final FileSplit fileSplit=createFileSplit(wrappedPath,split.getStart(),split.getLength());
  for (  String name : split.getSchema().stringPropertyNames()) {
    if (name.startsWith("serialization.")) {
      jobConf.set(name,split.getSchema().getProperty(name));
    }
  }
  try {
    return retry().stopOnIllegalExceptions().run("createRecordReader",new Callable<RecordReader<?,?>>(){
      @Override public RecordReader<?,?> call() throws IOException {
        return inputFormat.getRecordReader(fileSplit,jobConf,Reporter.NULL);
      }
    }
);
  }
 catch (  Exception e) {
    throw new PrestoException(HiveErrorCode.HIVE_CANNOT_OPEN_SPLIT.toErrorCode(),String.format("Error opening Hive split %s (offset=%s, length=%s) using %s: %s",split.getPath(),split.getStart(),split.getLength(),getInputFormatName(split.getSchema()),e.getMessage()),e);
  }
}
