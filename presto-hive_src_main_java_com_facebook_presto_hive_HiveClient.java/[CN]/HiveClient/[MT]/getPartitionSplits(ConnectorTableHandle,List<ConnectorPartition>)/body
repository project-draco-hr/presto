{
  checkNotNull(partitions,"partitions is null");
  ConnectorPartition partition=Iterables.getFirst(partitions,null);
  if (partition == null) {
    return new FixedSplitSource(connectorId,ImmutableList.<ConnectorSplit>of());
  }
  checkArgument(partition instanceof HivePartition,"Partition must be a hive partition");
  SchemaTableName tableName=((HivePartition)partition).getTableName();
  Optional<HiveBucket> bucket=((HivePartition)partition).getBucket();
  List<String> partitionNames=new ArrayList<>(Lists.transform(partitions,HiveUtil.partitionIdGetter()));
  Collections.sort(partitionNames,Ordering.natural().reverse());
  Table table;
  Iterable<org.apache.hadoop.hive.metastore.api.Partition> hivePartitions;
  try {
    table=metastore.getTable(tableName.getSchemaName(),tableName.getTableName());
    hivePartitions=getPartitions(table,tableName,partitionNames);
  }
 catch (  NoSuchObjectException e) {
    throw new TableNotFoundException(tableName);
  }
  return new HiveSplitSourceProvider(connectorId,table,partitionNames,hivePartitions,bucket,maxSplitSize,maxOutstandingSplits,maxSplitIteratorThreads,hdfsEnvironment,namenodeStats,directoryLister,executor,maxPartitionBatchSize).get();
}
