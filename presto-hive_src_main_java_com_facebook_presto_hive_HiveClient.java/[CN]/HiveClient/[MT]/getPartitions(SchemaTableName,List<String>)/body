{
  if (partitionNames.equals(ImmutableList.of(UNPARTITIONED_NAME))) {
    return ImmutableList.<org.apache.hadoop.hive.metastore.api.Partition>of(UnpartitionedPartition.INSTANCE);
  }
  Iterable<List<String>> partitionNameBatches=partitionExponentially(partitionNames,partitionBatchSize);
  Iterable<List<org.apache.hadoop.hive.metastore.api.Partition>> partitionBatches=transform(partitionNameBatches,new Function<List<String>,List<org.apache.hadoop.hive.metastore.api.Partition>>(){
    @Override public List<org.apache.hadoop.hive.metastore.api.Partition> apply(    List<String> partitionNameBatch){
      Exception exception=null;
      for (int attempt=0; attempt < 10; attempt++) {
        try {
          List<org.apache.hadoop.hive.metastore.api.Partition> partitions=metastore.getPartitionsByNames(tableName.getSchemaName(),tableName.getTableName(),partitionNameBatch);
          checkState(partitionNameBatch.size() == partitions.size(),"expected %s partitions but found %s",partitionNameBatch.size(),partitions.size());
          return partitions;
        }
 catch (        NoSuchObjectException|NullPointerException|IllegalStateException|IllegalArgumentException e) {
          throw Throwables.propagate(e);
        }
catch (        Exception e) {
          exception=e;
          log.debug("getPartitions attempt %s failed, will retry. Exception: %s",attempt,e.getMessage());
        }
        try {
          TimeUnit.SECONDS.sleep(1);
        }
 catch (        InterruptedException e) {
          Thread.currentThread().interrupt();
          throw Throwables.propagate(e);
        }
      }
      throw Throwables.propagate(exception);
    }
  }
);
  return concat(partitionBatches);
}
