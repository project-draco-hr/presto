{
  checkArgument(types != null && !types.isEmpty(),"Type is required");
  File dir=new File(outputDir);
  InputSupplier<InputStreamReader> inputSupplier;
  if (csvFile != null) {
    inputSupplier=Files.newReaderSupplier(new File(csvFile),Charsets.UTF_8);
  }
 else {
    inputSupplier=new InputSupplier<InputStreamReader>(){
      public InputStreamReader getInput(){
        return new InputStreamReader(System.in,Charsets.UTF_8);
      }
    }
;
  }
  ImmutableList.Builder<TupleInfo.Type> typeBuilder=ImmutableList.builder();
  ImmutableList.Builder<CsvColumnProcessor> csvColumns=ImmutableList.builder();
  ImmutableList.Builder<TupleStreamSerde> columnSerdeBuilder=ImmutableList.builder();
  for (  String type : types) {
    List<String> parts=ImmutableList.copyOf(Splitter.on('_').split(type));
    checkState(parts.size() == 2,"type format: <data_type>_<encoding> (e.g. long_raw, string_rle)");
    String dataType=parts.get(0);
    String encoding=parts.get(1);
switch (dataType) {
case "long":
      typeBuilder.add(Type.FIXED_INT_64);
    csvColumns.add(CsvReader.csvNumericColumn());
  break;
case "double":
typeBuilder.add(Type.DOUBLE);
csvColumns.add(CsvReader.csvDoubleColumn());
break;
case "string":
typeBuilder.add(Type.VARIABLE_BINARY);
csvColumns.add(CsvReader.csvStringColumn());
break;
case "fmillis":
typeBuilder.add(Type.FIXED_INT_64);
csvColumns.add(csvFloatMillisColumn());
break;
default :
throw new IllegalArgumentException("Unsupported type " + type);
}
columnSerdeBuilder.add(getTupleStreamSerde(encoding));
}
ImmutableList<TupleInfo.Type> columnTypes=typeBuilder.build();
TupleInfo tupleInfo=new TupleInfo(columnTypes);
CsvReader csvReader=new CsvReader(tupleInfo,inputSupplier,toChar(columnSeparator),csvColumns.build());
ImmutableList<TupleStreamSerde> columnSerdes=columnSerdeBuilder.build();
ImmutableList.Builder<OutputStream> outputs=ImmutableList.builder();
ImmutableList.Builder<TupleStreamWriter> tupleStreamWritersBuilder=ImmutableList.builder();
for (int index=0; index < columnTypes.size(); index++) {
OutputStream out=newOutputStreamSupplier(new File(dir,String.format("column%d.%s.data",index,types.get(index)))).getOutput();
tupleStreamWritersBuilder.add(columnSerdes.get(index).createTupleStreamWriter(new OutputStreamSliceOutput(out)));
outputs.add(out);
}
RowSource rowSource=csvReader.getInput();
ImmutableList<TupleStreamWriter> tupleStreamWriters=tupleStreamWritersBuilder.build();
for (TupleStream tupleStreamChunk : TupleStreamChunker.chunk(CHUNK_POSITION_WIDTH,rowSource)) {
DynamicSliceOutput sliceOutput=new DynamicSliceOutput((int)ESTIMATED_CHUNK_SIZE.toBytes());
TupleStreamSerdes.serialize(UncompressedSerde.INSTANCE,tupleStreamChunk,sliceOutput);
TupleStream copiedTupleStreamChunk=TupleStreamSerdes.deserialize(UncompressedSerde.INSTANCE,sliceOutput.slice());
for (int index=0; index < columnTypes.size(); index++) {
tupleStreamWriters.get(index).append(ColumnMappingTupleStream.map(copiedTupleStreamChunk,index));
}
}
for (TupleStreamWriter tupleStreamWriter : tupleStreamWriters) {
tupleStreamWriter.close();
}
rowSource.close();
for (OutputStream out : outputs.build()) {
out.close();
}
}
