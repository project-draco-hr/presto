{
  Session session=testSessionBuilder().setCatalog("hive").setSchema("tpch").build();
  LocalQueryRunner localQueryRunner=new LocalQueryRunner(session);
  InMemoryNodeManager nodeManager=localQueryRunner.getNodeManager();
  localQueryRunner.createCatalog("tpch",new TpchConnectorFactory(nodeManager,1),ImmutableMap.<String,String>of());
  File hiveDir=new File(tempDir,"hive_data");
  InMemoryHiveMetastore metastore=new InMemoryHiveMetastore(hiveDir);
  File tpchDataDir=new File(hiveDir,"tpch");
  metastore.createDatabase(new Database("tpch",null,tpchDataDir.toURI().toString(),null));
  HiveConnectorFactory hiveConnectorFactory=new HiveConnectorFactory("hive",ImmutableMap.of("node.environment","test"),HiveBenchmarkQueryRunner.class.getClassLoader(),new BridgingHiveMetastore(metastore),new TypeRegistry(),new GroupByHashPageIndexerFactory(),nodeManager);
  Map<String,String> hiveCatalogConfig=ImmutableMap.<String,String>builder().put("hive.metastore.uri","thrift://none.invalid:0").put("hive.max-split-size","10GB").build();
  localQueryRunner.createCatalog("hive",hiveConnectorFactory,hiveCatalogConfig);
  localQueryRunner.execute("CREATE TABLE orders AS SELECT * FROM tpch.sf1.orders");
  localQueryRunner.execute("CREATE TABLE lineitem AS SELECT * FROM tpch.sf1.lineitem");
  return localQueryRunner;
}
