{
  List<HiveColumnHandle> readColumns=ImmutableList.copyOf(filter(columns,not(isPartitionKeyPredicate())));
  List<Integer> readHiveColumnIndexes=ImmutableList.copyOf(transform(readColumns,hiveColumnIndexGetter()));
  ColumnProjectionUtils.appendReadColumns(configuration,readHiveColumnIndexes);
  final InputFormat<?,?> inputFormat=getInputFormat(configuration,schema,true);
  final JobConf jobConf=new JobConf(configuration);
  final FileSplit fileSplit=new FileSplit(path,start,length,(String[])null);
  for (  String name : schema.stringPropertyNames()) {
    if (name.startsWith("serialization.")) {
      jobConf.set(name,schema.getProperty(name));
    }
  }
  try {
    return retry().stopOnIllegalExceptions().run("createRecordReader",new Callable<RecordReader<?,?>>(){
      @Override public RecordReader<?,?> call() throws IOException {
        return inputFormat.getRecordReader(fileSplit,jobConf,Reporter.NULL);
      }
    }
);
  }
 catch (  Exception e) {
    throw new PrestoException(HIVE_CANNOT_OPEN_SPLIT,format("Error opening Hive split %s (offset=%s, length=%s) using %s: %s",path,start,length,getInputFormatName(schema),e.getMessage()),e);
  }
}
