{
  checkArgument(columnIds.size() == columnTypes.size(),"ids and types mismatch");
  checkArgument(isUnique(columnIds),"ids must be unique");
  fieldCount=columnIds.size();
  sampleWeightField=columnIds.indexOf(sampleWeightColumnId.or(-1L));
  Iterable<String> hiveTypeNames=ImmutableList.copyOf(transform(columnTypes,hiveTypeName()));
  List<String> columnNames=ImmutableList.copyOf(transform(columnIds,toStringFunction()));
  Properties properties=new Properties();
  properties.setProperty(META_TABLE_COLUMNS,Joiner.on(',').join(columnNames));
  properties.setProperty(META_TABLE_COLUMN_TYPES,Joiner.on(':').join(hiveTypeNames));
  properties.setProperty(HIVE_ORC_DEFAULT_COMPRESS.name(),SNAPPY.name());
  serializer=createSerializer(JOB_CONF,properties);
  recordWriter=createRecordWriter(new Path(target.toURI()),JOB_CONF,properties);
  tableInspector=getStandardStructObjectInspector(columnNames,getJavaObjectInspectors(columnTypes));
  structFields=ImmutableList.copyOf(tableInspector.getAllStructFieldRefs());
  row=tableInspector.create();
}
