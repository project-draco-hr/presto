{
  HiveSplit hiveSplit=checkType(split,HiveSplit.class,"split");
  String clientId=hiveSplit.getClientId();
  ConnectorSession session=hiveSplit.getSession();
  Path path=new Path(hiveSplit.getPath());
  long start=hiveSplit.getStart();
  long length=hiveSplit.getLength();
  Configuration configuration=hdfsEnvironment.getConfiguration(path);
  TupleDomain<HiveColumnHandle> effectivePredicate=hiveSplit.getEffectivePredicate();
  Properties schema=hiveSplit.getSchema();
  List<HivePartitionKey> partitionKeys=hiveSplit.getPartitionKeys();
  List<HiveColumnHandle> hiveColumns=ImmutableList.copyOf(transform(columns,hiveColumnHandle()));
  for (  HivePageSourceFactory pageSourceFactory : pageSourceFactories) {
    Optional<? extends ConnectorPageSource> pageSource=pageSourceFactory.createPageSource(configuration,session,path,start,length,schema,hiveColumns,partitionKeys,effectivePredicate,hiveStorageTimeZone);
    if (pageSource.isPresent()) {
      return pageSource.get();
    }
  }
  HiveRecordCursor recordCursor=getHiveRecordCursor(clientId,session,configuration,path,start,length,schema,effectivePredicate,partitionKeys,hiveColumns);
  if (recordCursor != null) {
    List<Type> columnTypes=ImmutableList.copyOf(transform(hiveColumns,nativeTypeGetter(typeManager)));
    return new RecordPageSource(columnTypes,recordCursor);
  }
  throw new RuntimeException("Could not find a file reader for split " + hiveSplit);
}
