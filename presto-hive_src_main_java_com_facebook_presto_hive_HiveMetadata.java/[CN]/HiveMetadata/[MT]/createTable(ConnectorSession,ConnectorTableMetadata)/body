{
  checkArgument(!isNullOrEmpty(tableMetadata.getOwner()),"Table owner is null or empty");
  SchemaTableName schemaTableName=tableMetadata.getTable();
  String schemaName=schemaTableName.getSchemaName();
  String tableName=schemaTableName.getTableName();
  List<String> partitionedBy=getPartitionedBy(tableMetadata.getProperties());
  Optional<HiveBucketProperty> bucketProperty=getBucketProperty(tableMetadata.getProperties());
  if (bucketProperty.isPresent()) {
    throw new PrestoException(NOT_SUPPORTED,"Writing to bucketed Hive table has been temporarily disabled");
  }
  List<HiveColumnHandle> columnHandles=getColumnHandles(connectorId,tableMetadata,ImmutableSet.copyOf(partitionedBy));
  HiveStorageFormat hiveStorageFormat=getHiveStorageFormat(tableMetadata.getProperties());
  Map<String,String> additionalTableParameters=tableParameterCodec.encode(tableMetadata.getProperties());
  LocationHandle locationHandle=locationService.forNewTable(session.getUser(),session.getQueryId(),schemaName,tableName);
  Path targetPath=locationService.targetPathRoot(locationHandle);
  createDirectory(session.getUser(),hdfsEnvironment,targetPath);
  Table table=buildTableObject(schemaName,tableName,tableMetadata.getOwner(),columnHandles,hiveStorageFormat,partitionedBy,bucketProperty,additionalTableParameters,targetPath);
  metastore.createTable(table);
}
