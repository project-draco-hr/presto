{
  SchemaTableName schemaTableName=tableMetadata.getTable();
  String schemaName=schemaTableName.getSchemaName();
  String tableName=schemaTableName.getTableName();
  List<String> partitionedBy=getPartitionedBy(tableMetadata.getProperties());
  Optional<HiveBucketProperty> bucketProperty=getBucketProperty(tableMetadata.getProperties());
  if (bucketProperty.isPresent() && !bucketWritingEnabled) {
    throw new PrestoException(NOT_SUPPORTED,"Writing to bucketed Hive table has been temporarily disabled");
  }
  List<HiveColumnHandle> columnHandles=getColumnHandles(connectorId,tableMetadata,ImmutableSet.copyOf(partitionedBy),typeTranslator);
  HiveStorageFormat hiveStorageFormat=getHiveStorageFormat(tableMetadata.getProperties());
  Map<String,String> additionalTableParameters=tableParameterCodec.encode(tableMetadata.getProperties());
  LocationHandle locationHandle=locationService.forNewTable(session.getUser(),session.getQueryId(),schemaName,tableName);
  Path targetPath=locationService.targetPathRoot(locationHandle);
  createDirectory(session.getUser(),hdfsEnvironment,targetPath);
  Table table=buildTableObject(schemaName,tableName,session.getUser(),columnHandles,hiveStorageFormat,partitionedBy,bucketProperty,additionalTableParameters,targetPath);
  PrincipalPrivilegeSet principalPrivilegeSet=buildInitialPrivilegeSet(table.getOwner());
  metastore.createTable(table,principalPrivilegeSet);
}
