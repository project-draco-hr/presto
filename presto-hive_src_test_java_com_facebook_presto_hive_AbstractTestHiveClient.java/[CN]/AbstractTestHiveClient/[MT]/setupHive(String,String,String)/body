{
  clientId=connectorId;
  database=databaseName;
  tablePartitionFormat=new SchemaTableName(database,"presto_test_partition_format");
  tableUnpartitioned=new SchemaTableName(database,"presto_test_unpartitioned");
  tableOffline=new SchemaTableName(database,"presto_test_offline");
  tableOfflinePartition=new SchemaTableName(database,"presto_test_offline_partition");
  view=new SchemaTableName(database,"presto_test_view");
  invalidTable=new SchemaTableName(database,INVALID_TABLE);
  tableBucketedStringInt=new SchemaTableName(database,"presto_test_bucketed_by_string_int");
  tableBucketedBigintBoolean=new SchemaTableName(database,"presto_test_bucketed_by_bigint_boolean");
  tableBucketedDoubleFloat=new SchemaTableName(database,"presto_test_bucketed_by_double_float");
  tablePartitionSchemaChange=new SchemaTableName(database,"presto_test_partition_schema_change");
  tablePartitionSchemaChangeNonCanonical=new SchemaTableName(database,"presto_test_partition_schema_change_non_canonical");
  temporaryCreateTable=new SchemaTableName(database,"tmp_presto_test_create_" + randomName());
  temporaryCreateRollbackTable=new SchemaTableName(database,"tmp_presto_test_create_" + randomName());
  temporaryCreateSampledTable=new SchemaTableName(database,"tmp_presto_test_create_" + randomName());
  temporaryCreateEmptyTable=new SchemaTableName(database,"tmp_presto_test_create_" + randomName());
  temporaryInsertTable=new SchemaTableName(database,"tmp_presto_test_insert_" + randomName());
  temporaryInsertIntoExistingPartitionTable=new SchemaTableName(database,"tmp_presto_test_insert_exsting_partitioned_" + randomName());
  temporaryInsertIntoNewPartitionTable=new SchemaTableName(database,"tmp_presto_test_insert_new_partitioned_" + randomName());
  temporaryInsertUnsupportedWriteType=new SchemaTableName(database,"tmp_presto_test_insert_unsupported_type_" + randomName());
  temporaryMetadataDeleteTable=new SchemaTableName(database,"tmp_presto_test_metadata_delete_" + randomName());
  temporaryRenameTableOld=new SchemaTableName(database,"tmp_presto_test_rename_" + randomName());
  temporaryRenameTableNew=new SchemaTableName(database,"tmp_presto_test_rename_" + randomName());
  temporaryCreateView=new SchemaTableName(database,"tmp_presto_test_create_" + randomName());
  invalidClientId="hive";
  invalidTableHandle=new HiveTableHandle(invalidClientId,database,INVALID_TABLE);
  invalidTableLayoutHandle=new HiveTableLayoutHandle(invalidClientId,ImmutableList.of(new HivePartition(invalidTable,TupleDomain.all(),"unknown",ImmutableMap.of(),Optional.empty())),TupleDomain.all());
  emptyTableLayoutHandle=new HiveTableLayoutHandle(invalidClientId,ImmutableList.of(),TupleDomain.none());
  dsColumn=new HiveColumnHandle(connectorId,"ds",HIVE_STRING,parseTypeSignature(StandardTypes.VARCHAR),-1,true);
  fileFormatColumn=new HiveColumnHandle(connectorId,"file_format",HIVE_STRING,parseTypeSignature(StandardTypes.VARCHAR),-1,true);
  dummyColumn=new HiveColumnHandle(connectorId,"dummy",HIVE_INT,parseTypeSignature(StandardTypes.BIGINT),-1,true);
  intColumn=new HiveColumnHandle(connectorId,"t_int",HIVE_INT,parseTypeSignature(StandardTypes.BIGINT),-1,true);
  invalidColumnHandle=new HiveColumnHandle(connectorId,INVALID_COLUMN,HIVE_STRING,parseTypeSignature(StandardTypes.VARCHAR),0,false);
  insertTableDestination=new SchemaTableName(database,"presto_insert_destination");
  insertTablePartitionedDestination=new SchemaTableName(database,"presto_insert_destination_partitioned");
  List<HivePartition> partitions=ImmutableList.<HivePartition>builder().add(new HivePartition(tablePartitionFormat,TupleDomain.<HiveColumnHandle>all(),"ds=2012-12-29/file_format=textfile/dummy=1",ImmutableMap.<ColumnHandle,NullableValue>builder().put(dsColumn,NullableValue.of(VARCHAR,utf8Slice("2012-12-29"))).put(fileFormatColumn,NullableValue.of(VARCHAR,utf8Slice("textfile"))).put(dummyColumn,NullableValue.of(BIGINT,1L)).build(),Optional.empty())).add(new HivePartition(tablePartitionFormat,TupleDomain.<HiveColumnHandle>all(),"ds=2012-12-29/file_format=sequencefile/dummy=2",ImmutableMap.<ColumnHandle,NullableValue>builder().put(dsColumn,NullableValue.of(VARCHAR,utf8Slice("2012-12-29"))).put(fileFormatColumn,NullableValue.of(VARCHAR,utf8Slice("sequencefile"))).put(dummyColumn,NullableValue.of(BIGINT,2L)).build(),Optional.empty())).add(new HivePartition(tablePartitionFormat,TupleDomain.<HiveColumnHandle>all(),"ds=2012-12-29/file_format=rctext/dummy=3",ImmutableMap.<ColumnHandle,NullableValue>builder().put(dsColumn,NullableValue.of(VARCHAR,utf8Slice("2012-12-29"))).put(fileFormatColumn,NullableValue.of(VARCHAR,utf8Slice("rctext"))).put(dummyColumn,NullableValue.of(BIGINT,3L)).build(),Optional.empty())).add(new HivePartition(tablePartitionFormat,TupleDomain.<HiveColumnHandle>all(),"ds=2012-12-29/file_format=rcbinary/dummy=4",ImmutableMap.<ColumnHandle,NullableValue>builder().put(dsColumn,NullableValue.of(VARCHAR,utf8Slice("2012-12-29"))).put(fileFormatColumn,NullableValue.of(VARCHAR,utf8Slice("rcbinary"))).put(dummyColumn,NullableValue.of(BIGINT,4L)).build(),Optional.empty())).build();
  partitionCount=partitions.size();
  tupleDomain=TupleDomain.fromFixedValues(ImmutableMap.of(dsColumn,NullableValue.of(VARCHAR,utf8Slice("2012-12-29"))));
  tableLayout=new ConnectorTableLayout(new HiveTableLayoutHandle(clientId,partitions,tupleDomain),Optional.empty(),TupleDomain.withColumnDomains(ImmutableMap.of(dsColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("2012-12-29"))),false),fileFormatColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("textfile")),Range.equal(VARCHAR,utf8Slice("sequencefile")),Range.equal(VARCHAR,utf8Slice("rctext")),Range.equal(VARCHAR,utf8Slice("rcbinary"))),false),dummyColumn,Domain.create(ValueSet.ofRanges(Range.equal(BIGINT,1L),Range.equal(BIGINT,2L),Range.equal(BIGINT,3L),Range.equal(BIGINT,4L)),false))),Optional.empty(),Optional.empty(),Optional.of(ImmutableList.of(TupleDomain.withColumnDomains(ImmutableMap.of(dsColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("2012-12-29"))),false),fileFormatColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("textfile"))),false),dummyColumn,Domain.create(ValueSet.ofRanges(Range.equal(BIGINT,1L)),false))),TupleDomain.withColumnDomains(ImmutableMap.of(dsColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("2012-12-29"))),false),fileFormatColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("sequencefile"))),false),dummyColumn,Domain.create(ValueSet.ofRanges(Range.equal(BIGINT,2L)),false))),TupleDomain.withColumnDomains(ImmutableMap.of(dsColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("2012-12-29"))),false),fileFormatColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("rctext"))),false),dummyColumn,Domain.create(ValueSet.ofRanges(Range.equal(BIGINT,3L)),false))),TupleDomain.withColumnDomains(ImmutableMap.of(dsColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("2012-12-29"))),false),fileFormatColumn,Domain.create(ValueSet.ofRanges(Range.equal(VARCHAR,utf8Slice("rcbinary"))),false),dummyColumn,Domain.create(ValueSet.ofRanges(Range.equal(BIGINT,4L)),false))))),ImmutableList.of());
  List<HivePartition> unpartitionedPartitions=ImmutableList.of(new HivePartition(tableUnpartitioned,TupleDomain.all()));
  unpartitionedTableLayout=new ConnectorTableLayout(new HiveTableLayoutHandle(clientId,unpartitionedPartitions,TupleDomain.all()),Optional.empty(),TupleDomain.all(),Optional.empty(),Optional.empty(),Optional.of(ImmutableList.of(TupleDomain.all())),ImmutableList.of());
  timeZone=DateTimeZone.forTimeZone(TimeZone.getTimeZone(timeZoneId));
}
