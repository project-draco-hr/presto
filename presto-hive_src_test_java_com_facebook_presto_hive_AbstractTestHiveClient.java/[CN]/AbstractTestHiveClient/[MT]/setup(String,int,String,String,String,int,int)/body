{
  setupHive(connectorName,databaseName,timeZoneId);
  HiveClientConfig hiveClientConfig=new HiveClientConfig();
  hiveClientConfig.setTimeZone(timeZoneId);
  String proxy=System.getProperty("hive.metastore.thrift.client.socks-proxy");
  if (proxy != null) {
    hiveClientConfig.setMetastoreSocksProxy(HostAndPort.fromString(proxy));
  }
  HiveCluster hiveCluster=new TestingHiveCluster(hiveClientConfig,host,port);
  HiveMetastore metastoreClient=new CachingHiveMetastore(hiveCluster,executor,Duration.valueOf("1m"),Duration.valueOf("15s"));
  HiveConnectorId connectorId=new HiveConnectorId(connectorName);
  HdfsConfiguration hdfsConfiguration=new HiveHdfsConfiguration(new HdfsConfigurationUpdater(hiveClientConfig));
  hdfsEnvironment=new HdfsEnvironment(hdfsConfiguration,hiveClientConfig);
  metadata=new HiveMetadata(connectorId,metastoreClient,hdfsEnvironment,timeZone,true,true,true,hiveClientConfig.getHiveStorageFormat(),new TypeRegistry());
  splitManager=new HiveSplitManager(connectorId,metastoreClient,new NamenodeStats(),hdfsEnvironment,new HadoopDirectoryLister(),timeZone,newDirectExecutorService(),maxOutstandingSplits,maxThreads,hiveClientConfig.getMinPartitionBatchSize(),hiveClientConfig.getMaxPartitionBatchSize(),hiveClientConfig.getMaxSplitSize(),hiveClientConfig.getMaxInitialSplitSize(),hiveClientConfig.getMaxInitialSplits(),false,false,false);
  recordSinkProvider=new HiveRecordSinkProvider(hdfsEnvironment);
  pageSourceProvider=new HivePageSourceProvider(hiveClientConfig,hdfsEnvironment,DEFAULT_HIVE_RECORD_CURSOR_PROVIDER,DEFAULT_HIVE_DATA_STREAM_FACTORIES,TYPE_MANAGER);
}
