{
  setupHive(connectorName,databaseName,timeZoneId);
  HiveClientConfig hiveClientConfig=new HiveClientConfig();
  hiveClientConfig.setTimeZone(timeZoneId);
  String proxy=System.getProperty("hive.metastore.thrift.client.socks-proxy");
  if (proxy != null) {
    hiveClientConfig.setMetastoreSocksProxy(HostAndPort.fromString(proxy));
  }
  HiveCluster hiveCluster=new TestingHiveCluster(hiveClientConfig,host,port);
  metastoreClient=new CachingHiveMetastore(hiveCluster,executor,Duration.valueOf("1m"),Duration.valueOf("15s"));
  HdfsEnvironment hdfsEnvironment=new HdfsEnvironment(new HdfsConfiguration(hiveClientConfig));
  HiveClient client=new HiveClient(new HiveConnectorId(connectorName),metastoreClient,new NamenodeStats(),hdfsEnvironment,new HadoopDirectoryLister(),timeZone,sameThreadExecutor(),hiveClientConfig.getMaxSplitSize(),maxOutstandingSplits,maxThreads,hiveClientConfig.getMinPartitionBatchSize(),hiveClientConfig.getMaxPartitionBatchSize(),hiveClientConfig.getMaxInitialSplitSize(),hiveClientConfig.getMaxInitialSplits(),false,true,true,hiveClientConfig.getHiveStorageFormat(),false,new TypeRegistry());
  metadata=client;
  splitManager=client;
  recordSinkProvider=client;
  pageSourceProvider=new HivePageSourceProvider(hiveClientConfig,hdfsEnvironment,DEFAULT_HIVE_RECORD_CURSOR_PROVIDERS,TYPE_MANAGER);
}
