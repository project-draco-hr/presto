{
  setupHive(connectorName,databaseName,timeZoneId);
  HiveClientConfig hiveClientConfig=new HiveClientConfig();
  String proxy=System.getProperty("hive.metastore.thrift.client.socks-proxy");
  if (proxy != null) {
    hiveClientConfig.setMetastoreSocksProxy(HostAndPort.fromString(proxy));
  }
  HiveCluster hiveCluster=new TestingHiveCluster(hiveClientConfig,host,port);
  ExecutorService executor=newCachedThreadPool(daemonThreadsNamed("hive-%s"));
  metastoreClient=new CachingHiveMetastore(hiveCluster,executor,Duration.valueOf("1m"),Duration.valueOf("15s"));
  HiveClient client=new HiveClient(new HiveConnectorId(connectorName),metastoreClient,new NamenodeStats(),new HdfsEnvironment(new HdfsConfiguration(hiveClientConfig)),DEFAULT_HIVE_RECORD_CURSOR_PROVIDERS,new HadoopDirectoryLister(),timeZone,sameThreadExecutor(),hiveClientConfig.getMaxSplitSize(),maxOutstandingSplits,maxThreads,hiveClientConfig.getMinPartitionBatchSize(),hiveClientConfig.getMaxPartitionBatchSize(),hiveClientConfig.getMaxInitialSplitSize(),hiveClientConfig.getMaxInitialSplits(),false,true,true,hiveClientConfig.getHiveStorageFormat(),false,new TypeRegistry());
  metadata=client;
  splitManager=client;
  recordSetProvider=client;
  recordSinkProvider=client;
}
