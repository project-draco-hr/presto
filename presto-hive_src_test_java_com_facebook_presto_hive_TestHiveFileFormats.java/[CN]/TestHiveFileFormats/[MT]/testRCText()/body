{
  JobConf jobConf=new JobConf();
  RCFileOutputFormat outputFormat=new RCFileOutputFormat();
  @SuppressWarnings("rawtypes") RCFileInputFormat inputFormat=new RCFileInputFormat();
  @SuppressWarnings("deprecation") SerDe serde=new ColumnarSerDe();
  File file=File.createTempFile("presto_test","rc-text");
  try {
    FileSplit split=createTestFile(file.getAbsolutePath(),outputFormat,serde,null);
    @SuppressWarnings("unchecked") RecordReader<?,BytesRefArrayWritable> recordReader=(RecordReader<?,BytesRefArrayWritable>)inputFormat.getRecordReader(split,jobConf,Reporter.NULL);
    Properties splitProperties=new Properties();
    splitProperties.setProperty("serialization.lib","org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe");
    splitProperties.setProperty("columns",COLUMN_NAMES_STRING);
    splitProperties.setProperty("columns.types",COLUMN_TYPES);
    RecordCursor cursor=new ColumnarTextHiveRecordCursor<>(recordReader,split.getLength(),splitProperties,new ArrayList<HivePartitionKey>(),getColumns(),DateTimeZone.getDefault(),DateTimeZone.getDefault());
    checkCursor(cursor);
  }
  finally {
    file.delete();
  }
}
